{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#r \"nuget: Microsoft.PowerBI.Api, 4.10.0\"\r\n",
        "#r \"nuget: Microsoft.IdentityModel.Clients.ActiveDirectory, 5.2.9\"\r\n",
        "#r \"nuget: Azure.Identity, 1.7.0\"\r\n",
        "#r \"nuget: Microsoft.Rest.ClientRuntime, 2.3.24\"\r\n",
        "#r \"nuget: Microsoft.Azure.Storage.Blob\"\r\n",
        "#r \"nuget: Microsoft.Azure.Storage.Common\"\r\n",
        "#r \"nuget: Azure.Security.KeyVault.Secrets, 4.4.0\"\r\n",
        "#r \"nuget: CsvHelper\"\r\n",
        "#r \"nuget: microsoft.aspnetcore.mvc.core\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%csharp\r\n",
        "using System;\r\n",
        "using System.Linq;\r\n",
        "using System.Configuration;\r\n",
        "using System.IO;\r\n",
        "using System.Security;\r\n",
        "using System.Reflection;\r\n",
        "using Microsoft.Rest;\r\n",
        "using Microsoft.Identity.Client;\r\n",
        "using Microsoft.PowerBI.Api;\r\n",
        "using System.Collections.Generic;\r\n",
        "using Microsoft.Spark.Sql;\r\n",
        "using System.Collections.Generic;\r\n",
        "using System.Net.Http;\r\n",
        "using System.Net.Http.Headers;\r\n",
        "using Newtonsoft.Json.Linq;\r\n",
        "using System.IO.Compression;\r\n",
        "using Microsoft.Azure.Storage.Blob;\r\n",
        "using System.Threading;\r\n",
        "using System.Threading.Tasks;\r\n",
        "using Microsoft.Spark.Sql;\r\n",
        "using Microsoft.Spark.Sql.Types;\r\n",
        "using Microsoft.Azure.Storage.Auth;\r\n",
        "using Microsoft.Azure.Storage;\r\n",
        "using Microsoft.Extensions.Logging;\r\n",
        "using System.Net;\r\n",
        "using Newtonsoft.Json;\r\n",
        "using System.Globalization;\r\n",
        "using Newtonsoft.Json.Serialization;\r\n",
        "using CsvHelper;\r\n",
        "using Microsoft.AspNetCore.Mvc;\r\n",
        "using Microsoft.PowerBI.Api;\r\n",
        "\r\n",
        "private static string spnAccessToken = string.Empty;\r\n",
        "\r\n",
        "static string GetSPNAccessToken(string applicationId, string applicationSecret, string tenantSpecificAuthority) {\r\n",
        "        if (spnAccessToken.Equals(string.Empty)) {\r\n",
        "        var appConfidential = ConfidentialClientApplicationBuilder.Create(applicationId)\r\n",
        "                                .WithClientSecret(applicationSecret)\r\n",
        "                                .WithAuthority(tenantSpecificAuthority)\r\n",
        "                                .Build();\r\n",
        "\r\n",
        "        string[] scopesDefault = new string[] { \"https://analysis.windows.net/powerbi/api/.default\" };\r\n",
        "        var authResult = appConfidential.AcquireTokenForClient(scopesDefault).ExecuteAsync().Result;\r\n",
        "        spnAccessToken = authResult.AccessToken;\r\n",
        "        }\r\n",
        "        return spnAccessToken;\r\n",
        "    }\r\n",
        "    \r\n",
        "public static PowerBIClient GetPowerBiAppOnlyClient(string applicationId\r\n",
        "                                                    ,string applicationSecret\r\n",
        "                                                    ,string tenantSpecificAuthority\r\n",
        "                                                    ,string urlPowerBiServiceApiRoot) {\r\n",
        "    var tokenCredentials = new TokenCredentials(GetSPNAccessToken(applicationId, applicationSecret, tenantSpecificAuthority), \"Bearer\");\r\n",
        "    return new PowerBIClient(new Uri(urlPowerBiServiceApiRoot), tokenCredentials);\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "csharp"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "from pyspark.sql.types import StructType,StructField,StringType,DateType\r\n",
        "from pyspark.sql.functions import *\r\n",
        "import os\r\n",
        "import re\r\n",
        "from notebookutils import mssparkutils\r\n",
        "\r\n",
        "keyvaultName = os.getenv(\"keyvaultName\")  # Create a spark.yarn.appMasterEnv.keyvaultName property in Apache Spark Configuration and store the keyvalut name\r\n",
        "applicationId = mssparkutils.credentials.getSecret(keyvaultName,\"secret name\",\"linked service name\") \r\n",
        "applicationSecret = mssparkutils.credentials.getSecret(keyvaultName,\"secret name\",\"linked service name\")\r\n",
        "storageConnString = mssparkutils.credentials.getSecret(keyvaultName,\"secret name\",\"linked service name\")\r\n",
        "tenantId = mssparkutils.credentials.getSecret(keyvaultName,\"secret name\",\"linked service name\")\r\n",
        "\r\n",
        "\r\n",
        "paramData = [(applicationId, applicationSecret, storageConnString, tenantId)]\r\n",
        "schema = StructType([ \\\r\n",
        "  StructField(\"applicationId\", StringType(), True), \\\r\n",
        "  StructField(\"applicationSecret\", StringType(), True), \\\r\n",
        "  StructField(\"storageConnString\", StringType(), True), \\\r\n",
        "  StructField(\"tenantId\", StringType(), True) \\\r\n",
        "])\r\n",
        "\r\n",
        "df = spark.createDataFrame(spark.sparkContext.parallelize(paramData), schema)\r\n",
        "df.createOrReplaceTempView(\"vw_tompo_params\")\r\n",
        "\r\n",
        "metadatadf = spark.read.option(\"header\", True).csv(\"/data/tompo/tompo_report_metadata.csv\")\r\n",
        "metadatadf.createOrReplaceTempView(\"vw_report_metadata\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%csharp\r\n",
        "public class TompoSecret\r\n",
        "{\r\n",
        "    public string applicationId { get; set; }\r\n",
        "    public string applicationSecret { get; set; }\r\n",
        "    public string storageConnString { get; set; }\r\n",
        "    public string tenantId { get; set; }\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "csharp"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%csharp\r\n",
        "using System.Collections.Generic;\r\n",
        "using System.IO;\r\n",
        "using System.Net.Http;\r\n",
        "using System.Net.Http.Headers;\r\n",
        "using Newtonsoft.Json.Linq;\r\n",
        "using System.IO.Compression;\r\n",
        "using Microsoft.Azure.Storage.Blob;\r\n",
        "using System.Threading;\r\n",
        "using System.Threading.Tasks;\r\n",
        "using Microsoft.Spark.Sql;\r\n",
        "using Microsoft.Spark.Sql.Types;\r\n",
        "using Microsoft.Azure.Storage.Auth;\r\n",
        "using Microsoft.Azure.Storage;\r\n",
        "using Microsoft.Extensions.Logging;\r\n",
        "using System.Net;\r\n",
        "using Newtonsoft.Json;\r\n",
        "using System.Globalization;\r\n",
        "using Newtonsoft.Json.Serialization;\r\n",
        "using CsvHelper;\r\n",
        "using Microsoft.AspNetCore.Mvc;\r\n",
        "using Microsoft.PowerBI.Api;\r\n",
        "\r\n",
        "public const string urlPowerBiServiceApiRoot = \"https://api.powerbi.com/\";\r\n",
        "private static string workspaceId = \"\";\r\n",
        "private static string reportId = \"\";\r\n",
        "private static string reportName = \"\";\r\n",
        "private static string applicationId = \"\";\r\n",
        "private static string applicationSecret = \"\";\r\n",
        "private static string tenantSpecificAuthority = \"\";\r\n",
        "private static string storageConnString = \"\";\r\n",
        "\r\n",
        "\r\n",
        "TompoSecret secretObj = new TompoSecret();\r\n",
        "var secretsdata = spark.Sql(\"SELECT * FROM vw_tompo_params\");\r\n",
        "\r\n",
        "secretsdata.Collect().ToList().ForEach(row => {\r\n",
        "    secretObj.applicationId = row[0].ToString();\r\n",
        "    secretObj.applicationSecret = row[1].ToString();\r\n",
        "    secretObj.storageConnString = row[2].ToString();\r\n",
        "    secretObj.tenantId = row[3].ToString();\r\n",
        "    }\r\n",
        ");\r\n",
        "\r\n",
        "applicationId = secretObj.applicationId;\r\n",
        "applicationSecret = secretObj.applicationSecret;\r\n",
        "tenantSpecificAuthority = \"https://login.microsoftonline.com/\" + secretObj.tenantId;\r\n",
        "storageConnString = secretObj.storageConnString;\r\n",
        "\r\n",
        "PowerBIClient pbiClient = GetPowerBiAppOnlyClient(applicationId, applicationSecret, tenantSpecificAuthority, urlPowerBiServiceApiRoot);\r\n",
        "var storageAccount = CloudStorageAccount.Parse(storageConnString);\r\n",
        "var blobClient = storageAccount.CreateCloudBlobClient();\r\n",
        "var container = blobClient.GetContainerReference(\"hrsisynapsefs\");\r\n",
        "\r\n",
        "var metadata = spark.Sql(\"SELECT * FROM vw_report_metadata where isActive=1\");\r\n",
        "\r\n",
        "metadata.Collect().ToList().ForEach(row => {\r\n",
        "    var workspaceName = row[0].ToString();\r\n",
        "    var workspaceId = row[1].ToString();\r\n",
        "    var reportName = row[2].ToString();\r\n",
        "    var reportId = row[3].ToString();\r\n",
        "    var modelName = row[4].ToString();\r\n",
        "    \r\n",
        "    var reportStream = pbiClient.Reports.ExportReport(new Guid(workspaceId), new Guid(reportId));\r\n",
        "    var blob = container.GetBlockBlobReference(\"data/tompo/tompo_layout/\" + reportName + \".pbix\");\r\n",
        "    blob.Properties.ContentType = \"mutipart/form-data\";\r\n",
        "    blob.UploadFromStream(reportStream);\r\n",
        "    reportStream.Close();\r\n",
        "    Console.WriteLine(reportName + \" Report has been donwloaded successfully\");\r\n",
        "\r\n",
        "    }\r\n",
        ");"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "csharp"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "from zipfile import ZipFile\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import pandas as pd\r\n",
        "import json\r\n",
        "from os.path import exists\r\n",
        "\r\n",
        "hrsiBasePath = os.getenv(\"hrsiBasePath\")\r\n",
        "\r\n",
        "                         #uncomment below block if running for first time, need to ad exists code\r\n",
        "#mssparkutils.fs.unmount(\"/hrsisynapsefs_temp\") \r\n",
        "#mssparkutils.fs.mount(hrsiBasePath, \r\n",
        "#\t\t\t\t\t\"/hrsisynapsefs_temp\",\r\n",
        "#\t\t\t\t\t{\"linkedService\":\"HRBIADLS\"}\r\n",
        "#\t\t\t\t\t)\r\n",
        "\r\n",
        "synpasefspath = \"/synfs/\" + mssparkutils.env.getJobId() + \"/hrsisynapsefs_temp\"\r\n",
        "\r\n",
        "outfilepath = synpasefspath + \"/data/tompo/tompo_parseroutput/tompo_output.csv\"\r\n",
        "\r\n",
        "file_exists = exists(outfilepath)\r\n",
        "\r\n",
        "if file_exists:\r\n",
        "    print(\"output file exists\")\r\n",
        "else:\r\n",
        "    outfiledf = pd.DataFrame(columns = ['WorkspaceName', 'ReportName', 'PageName', 'VisualType', 'Column', 'ModelName', 'LastRefreshedOn'])\r\n",
        "    outfiledf.to_csv(outfilepath, index=False)\r\n",
        "    print(\"created empty one time output file\")\r\n",
        "\r\n",
        "\r\n",
        "metadatadfdata = spark.sql(\"SELECT * FROM vw_report_metadata where isActive=1\")\r\n",
        "\r\n",
        "df = pd.DataFrame(columns = ['WorkspaceName', 'ReportName', 'PageName', 'VisualType', 'Column', 'ModelName', 'LastRefreshedOn'])\r\n",
        "\r\n",
        "for row in metadatadfdata.collect():\r\n",
        "    print(\"Working on file: \" + row[\"ReportName\"])\r\n",
        "    \r\n",
        "    f = ZipFile(synpasefspath + \"/data/tompo/tompo_layout/\" + row[\"ReportName\"] + \".pbix\", 'r')\r\n",
        "    f.extractall(synpasefspath + \"/data/tompo/tompo_layout/_temp\" + row[\"ReportName\"])\r\n",
        "    shutil.copyfile(synpasefspath + \"/data/tompo/tompo_layout/_temp\" + row[\"ReportName\"] + \"/Report/Layout\", synpasefspath + \"/data/tompo/tompo_layout/\" + row[\"ReportName\"] + \"_Layout\")\r\n",
        "    shutil.rmtree(synpasefspath + \"/data/tompo/tompo_layout/_temp\" + row[\"ReportName\"])\r\n",
        "    print(\"Retreived layout file for report \" + row[\"ReportName\"] + \".pbix\")\r\n",
        "\r\n",
        "    # code from here is to parse layout file and append in csv for POWER BI reporting\r\n",
        "    with  open(synpasefspath + \"/data/tompo/tompo_layout/\" + row[2] + \"_Layout\", encoding=\"utf-16le\", errors=\"backslashreplace\") as file:\r\n",
        "        data = file.read().strip()\r\n",
        "\r\n",
        "    layoutdata = json.loads(data)\r\n",
        "\r\n",
        "    outputlist = []\r\n",
        "\r\n",
        "    for section in layoutdata['sections']:\r\n",
        "\r\n",
        "        tabname = section['displayName']\r\n",
        "\r\n",
        "        for container in section['visualContainers']:\r\n",
        "            # if container['id'] != 0 :\r\n",
        "            configdict = json.loads(container['config'])\r\n",
        "\r\n",
        "            if 'singleVisual' in configdict:\r\n",
        "\r\n",
        "                visualtype = configdict['singleVisual']['visualType']\r\n",
        "\r\n",
        "                if 'projections' in configdict['singleVisual']:\r\n",
        "\r\n",
        "                    for key in configdict['singleVisual']['projections']:\r\n",
        "                        for query in configdict['singleVisual']['projections'][key]:\r\n",
        "\r\n",
        "                            data = query['queryRef'].split('.')[-1]\r\n",
        "                            outputlist.append(row[\"WorkspaceName\"])\r\n",
        "                            outputlist.append(row[\"ReportName\"])\r\n",
        "                            outputlist.append(tabname)\r\n",
        "                            outputlist.append(visualtype)\r\n",
        "                            outputlist.append(data)\r\n",
        "                            outputlist.append(row[\"ModelName\"])\r\n",
        "                            outputlist.append(str(pd.to_datetime('now').date()))\r\n",
        "                            \r\n",
        "                            df.loc[len(df)] = outputlist\r\n",
        "                            outputlist.clear()\r\n",
        "\r\n",
        "    outputdf = pd.read_csv(outfilepath, header='infer')\r\n",
        "\r\n",
        "    filterval = row[\"WorkspaceName\"].strip() + row[\"ReportName\"].strip()\r\n",
        "    outfiltereddf = outputdf[ (outputdf[\"WorkspaceName\"]+outputdf[\"ReportName\"] != filterval ) ]\r\n",
        "\r\n",
        "    finaldf = pd.concat([outfiltereddf, df])\r\n",
        "    \r\n",
        "    finaldf.to_csv(outfilepath, index=False)\r\n",
        "    df = df.iloc[:0]\r\n",
        "    print(\"Layout data is added to final csv for file: \" + row[\"ReportName\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "csharp"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}